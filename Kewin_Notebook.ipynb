{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kewindereniewicz/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import libraries for doing image analysis\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "import glob\n",
    "import os\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import StratifiedKFold as KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from pylab import cm\n",
    "from skimage import segmentation\n",
    "from skimage.morphology import watershed\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from skimage.feature import peak_local_max\n",
    "# make graphics inline\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132103.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66467.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9143.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20630.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33689.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  class\n",
       "0  132103.jpg      0\n",
       "1   66467.jpg      0\n",
       "2    9143.jpg      0\n",
       "3   20630.jpg      0\n",
       "4   33689.jpg      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_labels = pd.read_csv('data/train_onelabel.csv')\n",
    "df_train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown_unclassified</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown_sticks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>protist_star</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>copepod_cyclopoid_oithona</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hydromedusae_solmundella</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       label  class\n",
       "0       unknown_unclassified      0\n",
       "1             unknown_sticks      1\n",
       "2               protist_star      2\n",
       "3  copepod_cyclopoid_oithona      3\n",
       "4   hydromedusae_solmundella      4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_map = pd.read_csv('data/label_map.txt', sep=\" \", header=None, names=[\"label\", \"class\"])\n",
    "df_label_map.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "\n",
    "def preprocess_img(img):\n",
    "    # rescale to standard size\n",
    "    img = resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train_images/100088.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEQ0iYRIRJNIiEQ0iYRI5P8AKGBKMajNPeMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dede128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example image\n",
    "example_file = glob.glob('data/train_images/*.jpg')[12]\n",
    "print(example_file)\n",
    "im = imread(example_file, as_grey=True)\n",
    "plt.imshow(im, cmap=cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10deceba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_im = preprocess_img(im)\n",
    "plt.imshow(new_im, cmap=cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label(file_name):\n",
    "    return df_train_labels.loc[df_train_labels['image'] == file_name]['class'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 24204\n",
      "Reading images...\n",
      "5.0 % done\n",
      "10.0 % done\n",
      "15.0 % done\n",
      "20.0 % done\n",
      "25.0 % done\n",
      "30.0 % done\n",
      "35.0 % done\n",
      "40.0 % done\n",
      "45.0 % done\n",
      "50.0 % done\n",
      "55.0 % done\n",
      "60.0 % done\n",
      "65.0 % done\n",
      "70.0 % done\n",
      "75.0 % done\n",
      "80.0 % done\n",
      "85.0 % done\n",
      "90.0 % done\n",
      "95.0 % done\n",
      "100.0 % done\n"
     ]
    }
   ],
   "source": [
    "#get the total training images\n",
    "number_of_images = 0\n",
    "for _, _, fileNames in os.walk('data/train_images'): \n",
    "    for fileName in fileNames:\n",
    "        # Only read in the images\n",
    "        if fileName[-4:] != \".jpg\":\n",
    "            continue\n",
    "        number_of_images += 1\n",
    "        \n",
    "print('Number of images:', number_of_images)\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "i = 0\n",
    "\n",
    "print('Reading images...')\n",
    "\n",
    "for root, _, file_names in os.walk('data/train_images'): # change in train_images\n",
    "    for file_name in file_names:\n",
    "        # Only read in the images\n",
    "        if fileName[-4:] != \".jpg\":\n",
    "            continue\n",
    "        \n",
    "        img_path = \"{0}{1}{2}\".format(root, os.sep, file_name)\n",
    "        img = preprocess_img(imread(img_path, as_grey=True))\n",
    "        imgs.append(img)\n",
    "        \n",
    "        label = get_label(file_name)\n",
    "        labels.append(label)\n",
    "        \n",
    "        i += 1\n",
    "        # report progress for each 5% done  \n",
    "        report = [int((j+1)*number_of_images/20.) for j in range(20)]\n",
    "        if i in report: print(np.ceil(i *100.0 / number_of_images), \"% done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24204, 64, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(imgs, dtype='float32')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24204, 1, 64, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(X.shape[0], 1, IMG_SIZE, IMG_SIZE)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24204, 121)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np_utils.to_categorical(labels)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 6132\n",
      "Reading test images...\n",
      "5.0 % done\n",
      "10.0 % done\n",
      "15.0 % done\n",
      "20.0 % done\n",
      "25.0 % done\n",
      "30.0 % done\n",
      "35.0 % done\n",
      "40.0 % done\n",
      "45.0 % done\n",
      "50.0 % done\n",
      "55.0 % done\n",
      "60.0 % done\n",
      "65.0 % done\n",
      "70.0 % done\n",
      "75.0 % done\n",
      "80.0 % done\n",
      "85.0 % done\n",
      "90.0 % done\n",
      "95.0 % done\n",
      "100.0 % done\n"
     ]
    }
   ],
   "source": [
    "#get the total training images\n",
    "number_of_images = 0\n",
    "for _, _, fileNames in os.walk('data/test_images'): \n",
    "    for fileName in fileNames:\n",
    "        # Only read in the images\n",
    "        if fileName[-4:] != \".jpg\":\n",
    "            continue\n",
    "        number_of_images += 1\n",
    "        \n",
    "print('Number of images:', number_of_images)\n",
    "\n",
    "imgs = []\n",
    "test_img_names = []\n",
    "i = 0\n",
    "\n",
    "print('Reading test images...')\n",
    "\n",
    "for root, _, file_names in os.walk('data/test_images'): # change in train_images\n",
    "    for file_name in file_names:\n",
    "        # Only read in the images\n",
    "        if fileName[-4:] != \".jpg\":\n",
    "            continue\n",
    "        \n",
    "        img_path = \"{0}{1}{2}\".format(root, os.sep, file_name)\n",
    "        img = preprocess_img(imread(img_path, as_grey=True))\n",
    "        imgs.append(img)\n",
    "        \n",
    "        test_img_names.append(file_name)\n",
    "        \n",
    "        i += 1\n",
    "        # report progress for each 5% done  \n",
    "        report = [int((j+1)*number_of_images/20.) for j in range(20)]\n",
    "        if i in report: print(np.ceil(i *100.0 / number_of_images), \"% done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 64, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(imgs, dtype='float32')\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 1, 64, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 1, IMG_SIZE, IMG_SIZE)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 121\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', \n",
    "                     input_shape=(1, IMG_SIZE, IMG_SIZE), \n",
    "                     activation='relu', data_format='channels_first'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', data_format='channels_first'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu', data_format='channels_first'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', data_format='channels_first'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu', data_format='channels_first'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', data_format='channels_first'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(512, activation='relu')) # added\n",
    "    #model.add(Dropout(0.2)) # added\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    from skimage.io import imread\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from skimage.transform import resize\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.ensemble import RandomForestClassifier as RF\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import glob\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import cross_validation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.cross_validation import StratifiedKFold as KFold\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import classification_report\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from matplotlib import pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from matplotlib import colors\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from pylab import cm\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from skimage import segmentation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from skimage.morphology import watershed\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from skimage import measure\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from skimage import morphology\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from scipy import ndimage\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from skimage.feature import peak_local_max\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import warnings\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Dropout, Activation, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Conv2D, MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt.base import Trials\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.python.client import device_lib\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.image import ImageDataGenerator\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'conditional': hp.choice('conditional', ['three', 'four']),\n",
      "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
      "        'Dropout_3': hp.uniform('Dropout_3', 0, 1),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [32, 64]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: IMG_SIZE = 64\n",
      "   3: \n",
      "   4: df_train_labels = pd.read_csv('data/train_onelabel.csv')\n",
      "   5: \n",
      "   6: number_of_images = 0\n",
      "   7: for _, _, fileNames in os.walk('data/train_images'): \n",
      "   8:     for fileName in fileNames:\n",
      "   9:         # Only read in the images\n",
      "  10:         if fileName[-4:] != \".jpg\":\n",
      "  11:             continue\n",
      "  12:         number_of_images += 1\n",
      "  13: \n",
      "  14: print('Number of images:', number_of_images)\n",
      "  15: \n",
      "  16: imgs = []\n",
      "  17: labels = []\n",
      "  18: i = 0\n",
      "  19: \n",
      "  20: print('Reading images...')\n",
      "  21: \n",
      "  22: for root, _, file_names in os.walk('data/train_images'): # change in train_images\n",
      "  23:     for file_name in file_names:\n",
      "  24:         # Only read in the images\n",
      "  25:         if fileName[-4:] != \".jpg\":\n",
      "  26:             continue\n",
      "  27: \n",
      "  28:         img_path = \"{0}{1}{2}\".format(root, os.sep, file_name)\n",
      "  29:         img = resize(imread(img_path, as_grey=True), (121, 121))\n",
      "  30:         imgs.append(img)\n",
      "  31: \n",
      "  32:         label = df_train_labels.loc[df_train_labels['image'] == file_name]['class'].values[0]\n",
      "  33:         labels.append(label)\n",
      "  34: \n",
      "  35:         i += 1\n",
      "  36:         # report progress for each 5% done  \n",
      "  37:         report = [int((j+1)*number_of_images/20.) for j in range(20)]\n",
      "  38:         if i in report: print(np.ceil(i *100.0 / number_of_images), \"% done\")\n",
      "  39: X = np.array(imgs, dtype='float32')\n",
      "  40: X = X.reshape(X.shape[0], 1, 121, 121)\n",
      "  41: Y = np_utils.to_categorical(labels)\n",
      "  42: \n",
      "  43: x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
      "  44: \n",
      "  45: \n",
      "  46: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     model = Sequential()\n",
      "   4:     model.add(Conv2D(32, (3, 3), padding='same', \n",
      "   5:                      input_shape=(1, 121, 121), \n",
      "   6:                      activation='relu', data_format='channels_first'))\n",
      "   7:     model.add(Conv2D(32, (3, 3), activation='relu', data_format='channels_first'))\n",
      "   8:     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "   9:     model.add(Dropout(space['Dropout']))\n",
      "  10:     model.add(Conv2D(64, (3, 3), padding='same',\n",
      "  11:                      activation='relu', data_format='channels_first'))\n",
      "  12:     model.add(Conv2D(64, (3, 3), activation='relu', data_format='channels_first'))\n",
      "  13:     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "  14:     model.add(Dropout(space['Dropout_1']))\n",
      "  15:     model.add(Conv2D(128, (3, 3), padding='same',\n",
      "  16:                      activation='relu', data_format='channels_first'))\n",
      "  17:     model.add(Conv2D(128, (3, 3), activation='relu', data_format='channels_first'))\n",
      "  18:     \n",
      "  19:     if conditional(space['conditional']) == 'four':\n",
      "  20:         model.add(MaxPooling2D(pool_size=(2, 2)))\n",
      "  21:         model.add(Dropout(space['Dropout_2']))\n",
      "  22:         \n",
      "  23:     model.add(Flatten())\n",
      "  24:     model.add(Dense(512, activation='relu')) # added\n",
      "  25:     model.add(Dropout(space['Dropout_3'])) # added\n",
      "  26:     model.add(Dense(512, activation='relu'))\n",
      "  27:     model.add(Dropout(0.4))\n",
      "  28:     model.add(Dense(121, activation='softmax'))\n",
      "  29:     \n",
      "  30:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
      "  31:                   optimizer=space['optimizer'])\n",
      "  32: \n",
      "  33:     model.fit(x_train, y_train,\n",
      "  34:               batch_size=space['batch_size'],\n",
      "  35:               epochs=1,\n",
      "  36:               verbose=2,\n",
      "  37:               validation_data=(x_test, y_test))\n",
      "  38:     \n",
      "  39:     score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
      "  40:     \n",
      "  41:     print('Test accuracy:', acc)\n",
      "  42:     \n",
      "  43:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  44: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-447290df75ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m                                           \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                                           \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                                         notebook_name='AML_17_Kaggle_Plankton_Identification')\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\u001b[0m\n\u001b[1;32m     65\u001b[0m                                      \u001b[0mfull_model_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                      verbose=verbose)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperas/optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[0;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[1;32m    131\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m              return_argmin=True),\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AML/Project/temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[0;34m(space)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimization when creating a model\n",
    "\n",
    "from hyperopt.base import Trials\n",
    "from hyperopt import STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# artificial function returning train and test data\n",
    "def data():\n",
    "    IMG_SIZE = 64\n",
    "    \n",
    "    df_train_labels = pd.read_csv('data/train_onelabel.csv')\n",
    "\n",
    "    number_of_images = 0\n",
    "    for _, _, fileNames in os.walk('data/train_images'): \n",
    "        for fileName in fileNames:\n",
    "            # Only read in the images\n",
    "            if fileName[-4:] != \".jpg\":\n",
    "                continue\n",
    "            number_of_images += 1\n",
    "\n",
    "    print('Number of images:', number_of_images)\n",
    "\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "\n",
    "    print('Reading images...')\n",
    "\n",
    "    for root, _, file_names in os.walk('data/train_images'): # change in train_images\n",
    "        for file_name in file_names:\n",
    "            # Only read in the images\n",
    "            if fileName[-4:] != \".jpg\":\n",
    "                continue\n",
    "\n",
    "            img_path = \"{0}{1}{2}\".format(root, os.sep, file_name)\n",
    "            img = resize(imread(img_path, as_grey=True), (121, 121))\n",
    "            imgs.append(img)\n",
    "\n",
    "            label = df_train_labels.loc[df_train_labels['image'] == file_name]['class'].values[0]\n",
    "            labels.append(label)\n",
    "\n",
    "            i += 1\n",
    "            # report progress for each 5% done  \n",
    "            report = [int((j+1)*number_of_images/20.) for j in range(20)]\n",
    "            if i in report: print(np.ceil(i *100.0 / number_of_images), \"% done\")\n",
    "    X = np.array(imgs, dtype='float32')\n",
    "    X = X.reshape(X.shape[0], 1, 121, 121)\n",
    "    Y = np_utils.to_categorical(labels)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', \n",
    "                     input_shape=(1, 121, 121), \n",
    "                     activation='relu', data_format='channels_first'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', data_format='channels_first'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu', data_format='channels_first'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', data_format='channels_first'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu', data_format='channels_first'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', data_format='channels_first'))\n",
    "    \n",
    "    if conditional({{choice(['three', 'four'])}}) == 'four':\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout({{uniform(0, 1)}}))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu')) # added\n",
    "    model.add(Dropout({{uniform(0, 1)}})) # added\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(121, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size={{choice([32, 64])}},\n",
    "              epochs=1,\n",
    "              verbose=2,\n",
    "              validation_data=(x_test, y_test))\n",
    "    \n",
    "    score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    print('Test accuracy:', acc)\n",
    "    \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                        notebook_name='AML_17_Kaggle_Plankton_Identification')\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = data()\n",
    "\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, Y_test))\n",
    "\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "24204/24204 [==============================] - 2101s 87ms/step - loss: 4.2107 - acc: 0.0940\n",
      "Epoch 2/25\n",
      "24204/24204 [==============================] - 2199s 91ms/step - loss: 3.8753 - acc: 0.1347\n",
      "Epoch 3/25\n",
      " 8320/24204 [=========>....................] - ETA: 28:31 - loss: 3.5887 - acc: 0.1855"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=32, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ CategoryAccuracy = \\frac{1}{N} \\sum_{y_i = \\hat{y}_i} 1,$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X, Y, verbose=0)\n",
    "print(\"Accuracy: \", score[1])\n",
    "#.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame(list(zip(test_img_names, y_pred)),columns=['image','class'])\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export dataframe to csv file for submission\n",
    "df_submit.to_csv('submission', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             featurewise_std_normalization=False,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10.)\n",
    "\n",
    "datagen.fit(X)\n",
    "\n",
    "# Reinitialize model and compile\n",
    "model = cnn_model()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# Train again\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "model.fit_generator(datagen.flow(X, Y, batch_size=batch_size), steps_per_epoch=X.shape[0], epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X, Y, verbose=0)\n",
    "print(\"Accuracy: \", score[1])\n",
    "\n",
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submit2 = pd.DataFrame(list(zip(test_img_names, y_pred)),columns=['image','class'])\n",
    "df_submit2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export dataframe to csv file for submission\n",
    "df_submit2.to_csv('submission2.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             featurewise_std_normalization=False,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10.)\n",
    "# fit parameters from data\n",
    "datagen.fit(X)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, Y_batch in datagen.flow(X, Y, batch_size=9, shuffle=False):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].reshape(25, 25), cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip images vertically\n",
    "datagen = ImageDataGenerator(vertical_flip=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X)\n",
    "# Configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X, Y, batch_size=9, shuffle=False):\n",
    "    # Show 9 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].reshape(25, 25), cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip images vertically\n",
    "datagen = ImageDataGenerator(vertical_flip=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(X)\n",
    "# Configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X, Y, batch_size=9, shuffle=False):\n",
    "    # Show 9 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].reshape(25, 25), cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
