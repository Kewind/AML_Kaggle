{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kewin\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import libraries for doing image analysis\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "import glob\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import StratifiedKFold as KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from pylab import cm\n",
    "from skimage import segmentation\n",
    "from skimage.morphology import watershed\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "# make graphics inline\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "channels_first\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "print(K.image_data_format())\n",
    "K.set_image_data_format('channels_first')\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16118063148174085873\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3282167398\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 1063493276835867971\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# check for GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132103.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66467.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9143.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20630.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33689.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  class\n",
       "0  132103.jpg      0\n",
       "1   66467.jpg      0\n",
       "2    9143.jpg      0\n",
       "3   20630.jpg      0\n",
       "4   33689.jpg      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_labels = pd.read_csv(os.path.join(data_dir,'train_onelabel.csv'))\n",
    "df_train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown_unclassified</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown_sticks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>protist_star</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>copepod_cyclopoid_oithona</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hydromedusae_solmundella</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       label  class\n",
       "0       unknown_unclassified      0\n",
       "1             unknown_sticks      1\n",
       "2               protist_star      2\n",
       "3  copepod_cyclopoid_oithona      3\n",
       "4   hydromedusae_solmundella      4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_map = pd.read_csv(os.path.join(data_dir,'label_map.txt'), sep=\" \", header=None, names=[\"label\", \"class\"])\n",
    "df_label_map.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # rescale to standard size\n",
    "    img = resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    return img\n",
    "\n",
    "def get_label(file_name):\n",
    "    return df_train_labels.loc[df_train_labels['image'] == file_name]['class'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 24204\n",
      "Reading images...\n",
      "5.0 % done\n",
      "10.0 % done\n",
      "15.0 % done\n",
      "20.0 % done\n",
      "25.0 % done\n",
      "30.0 % done\n",
      "35.0 % done\n",
      "40.0 % done\n",
      "45.0 % done\n",
      "50.0 % done\n",
      "55.0 % done\n",
      "60.0 % done\n",
      "65.0 % done\n",
      "70.0 % done\n",
      "75.0 % done\n",
      "80.0 % done\n",
      "85.0 % done\n",
      "90.0 % done\n",
      "95.0 % done\n",
      "100.0 % done\n"
     ]
    }
   ],
   "source": [
    "#get the total training images\n",
    "number_of_images = 0\n",
    "for _, _, fileNames in os.walk(os.path.join(data_dir,'train_images')): \n",
    "    for fileName in fileNames:\n",
    "        # Only read in the images\n",
    "        if fileName[-4:] != \".jpg\":\n",
    "            continue\n",
    "        number_of_images += 1\n",
    "        \n",
    "print('Number of images:', number_of_images)\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "i = 0\n",
    "\n",
    "print('Reading images...')\n",
    "\n",
    "for root, _, file_names in os.walk(os.path.join(data_dir,'train_images')): # change in train_images\n",
    "    for file_name in file_names:\n",
    "        # Only read in the images\n",
    "        if fileName[-4:] != \".jpg\":\n",
    "            continue\n",
    "        \n",
    "        img_path = \"{0}{1}{2}\".format(root, os.sep, file_name)\n",
    "        img = preprocess_img(imread(img_path, as_grey=True))\n",
    "        imgs.append(img)\n",
    "        \n",
    "        label = get_label(file_name)\n",
    "        labels.append(label)\n",
    "        \n",
    "        i += 1\n",
    "        # report progress for each 5% done  \n",
    "        report = [int((j+1)*number_of_images/20.) for j in range(20)]\n",
    "        if i in report: print(np.ceil(i *100.0 / number_of_images), \"% done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24204, 64, 64)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(imgs, dtype='float32')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24204, 1, 64, 64)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(X.shape[0], 1, IMG_SIZE, IMG_SIZE)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24204, 121)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np_utils.to_categorical(labels)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 6132\n",
      "Reading test images...\n",
      "5.0 % done\n",
      "10.0 % done\n",
      "15.0 % done\n",
      "20.0 % done\n",
      "25.0 % done\n",
      "30.0 % done\n",
      "35.0 % done\n",
      "40.0 % done\n",
      "45.0 % done\n",
      "50.0 % done\n",
      "55.0 % done\n",
      "60.0 % done\n",
      "65.0 % done\n",
      "70.0 % done\n",
      "75.0 % done\n",
      "80.0 % done\n",
      "85.0 % done\n",
      "90.0 % done\n",
      "95.0 % done\n",
      "100.0 % done\n"
     ]
    }
   ],
   "source": [
    "#get the total test images\n",
    "number_of_images = 0\n",
    "for _, _, fileNames in os.walk(os.path.join(data_dir,'test_images')): \n",
    "    for fileName in fileNames:\n",
    "        # Only read in the images\n",
    "        if fileName[-4:] != \".jpg\":\n",
    "            continue\n",
    "        number_of_images += 1\n",
    "        \n",
    "print('Number of images:', number_of_images)\n",
    "\n",
    "imgs = []\n",
    "test_img_names = []\n",
    "i = 0\n",
    "\n",
    "print('Reading test images...')\n",
    "\n",
    "for root, _, file_names in os.walk(os.path.join(data_dir,'test_images')): # change in train_images\n",
    "    for file_name in file_names:\n",
    "        # Only read in the images\n",
    "        if fileName[-4:] != \".jpg\":\n",
    "            continue\n",
    "        \n",
    "        img_path = \"{0}{1}{2}\".format(root, os.sep, file_name)\n",
    "        img = preprocess_img(imread(img_path, as_grey=True))\n",
    "        imgs.append(img)\n",
    "        \n",
    "        test_img_names.append(file_name)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        report = [int((j+1)*number_of_images/20.) for j in range(20)]\n",
    "        if i in report: print(np.ceil(i *100.0 / number_of_images), \"% done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 64, 64)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(imgs, dtype='float32')\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 1, 64, 64)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 1, IMG_SIZE, IMG_SIZE)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Keras Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(1, IMG_SIZE, IMG_SIZE), data_format='channels_first'))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "    model.add(Conv2D(32, (3, 3), data_format='channels_first'))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', data_format='channels_first'))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "    model.add(Conv2D(64, (3, 3), data_format='channels_first'))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "    model.add(Conv2D(128, (3, 3), data_format='channels_first'))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), data_format='channels_first'))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "    model.add(Conv2D(256, (3, 3), data_format='channels_first'))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.3))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallback = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "esCallback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=5,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "checkpointCallback = keras.callbacks.ModelCheckpoint('./best_model_checkpoint.hdf5', monitor='val_loss',\n",
    "                                verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def random_rot90(x):\n",
    "    return np.rot90(x, randint(0, 3), axes=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "303/303 [==============================] - 96s 317ms/step - loss: 4.1166 - acc: 0.0960 - val_loss: 3.8109 - val_acc: 0.1111\n",
      "Epoch 2/250\n",
      "303/303 [==============================] - 94s 311ms/step - loss: 3.5782 - acc: 0.1657 - val_loss: 3.1239 - val_acc: 0.2535\n",
      "Epoch 3/250\n",
      "303/303 [==============================] - 95s 313ms/step - loss: 3.0755 - acc: 0.2516 - val_loss: 2.5733 - val_acc: 0.3425\n",
      "Epoch 4/250\n",
      "303/303 [==============================] - 95s 313ms/step - loss: 2.6945 - acc: 0.3144 - val_loss: 2.2799 - val_acc: 0.3931\n",
      "Epoch 5/250\n",
      "303/303 [==============================] - 95s 313ms/step - loss: 2.4367 - acc: 0.3580 - val_loss: 2.0790 - val_acc: 0.4383\n",
      "Epoch 6/250\n",
      "303/303 [==============================] - 95s 315ms/step - loss: 2.2689 - acc: 0.3929 - val_loss: 1.9595 - val_acc: 0.4613\n",
      "Epoch 7/250\n",
      "303/303 [==============================] - 95s 313ms/step - loss: 2.1300 - acc: 0.4196 - val_loss: 1.8685 - val_acc: 0.4861\n",
      "Epoch 8/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 2.0420 - acc: 0.4376 - val_loss: 1.7848 - val_acc: 0.4865\n",
      "Epoch 9/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.9396 - acc: 0.4616 - val_loss: 1.6567 - val_acc: 0.5315\n",
      "Epoch 10/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.8719 - acc: 0.4757 - val_loss: 1.6498 - val_acc: 0.5447\n",
      "Epoch 11/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.8019 - acc: 0.4972 - val_loss: 1.5731 - val_acc: 0.5482\n",
      "Epoch 12/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.7474 - acc: 0.5071 - val_loss: 1.5139 - val_acc: 0.5650\n",
      "Epoch 13/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.6963 - acc: 0.5186 - val_loss: 1.5025 - val_acc: 0.5712\n",
      "Epoch 14/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.6605 - acc: 0.5254 - val_loss: 1.4174 - val_acc: 0.5951\n",
      "Epoch 15/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.6201 - acc: 0.5347 - val_loss: 1.3779 - val_acc: 0.5980\n",
      "Epoch 16/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.5913 - acc: 0.5415 - val_loss: 1.3884 - val_acc: 0.5920\n",
      "Epoch 17/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.5634 - acc: 0.5503 - val_loss: 1.3835 - val_acc: 0.5997\n",
      "Epoch 18/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.5513 - acc: 0.5488 - val_loss: 1.3760 - val_acc: 0.5891\n",
      "Epoch 19/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.5153 - acc: 0.5613 - val_loss: 1.2943 - val_acc: 0.6135\n",
      "Epoch 20/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.4822 - acc: 0.5688 - val_loss: 1.3394 - val_acc: 0.6131\n",
      "Epoch 21/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.4697 - acc: 0.5730 - val_loss: 1.3406 - val_acc: 0.6160\n",
      "Epoch 22/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.4636 - acc: 0.5743 - val_loss: 1.3027 - val_acc: 0.6191\n",
      "Epoch 23/250\n",
      "303/303 [==============================] - 95s 314ms/step - loss: 1.4379 - acc: 0.5813 - val_loss: 1.2604 - val_acc: 0.6298\n",
      "Epoch 24/250\n",
      "303/303 [==============================] - 95s 312ms/step - loss: 1.4248 - acc: 0.5834 - val_loss: 1.2619 - val_acc: 0.6313\n",
      "Epoch 25/250\n",
      "303/303 [==============================] - 95s 314ms/step - loss: 1.4123 - acc: 0.5817 - val_loss: 1.2542 - val_acc: 0.6304\n",
      "Epoch 26/250\n",
      "303/303 [==============================] - 95s 314ms/step - loss: 1.3904 - acc: 0.5891 - val_loss: 1.2443 - val_acc: 0.6395\n",
      "Epoch 27/250\n",
      "303/303 [==============================] - 94s 311ms/step - loss: 1.3883 - acc: 0.5919 - val_loss: 1.2282 - val_acc: 0.6400\n",
      "Epoch 28/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.3536 - acc: 0.5983 - val_loss: 1.2287 - val_acc: 0.6364\n",
      "Epoch 29/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.3506 - acc: 0.6010 - val_loss: 1.1982 - val_acc: 0.6497\n",
      "Epoch 30/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.3379 - acc: 0.6029 - val_loss: 1.2058 - val_acc: 0.6466\n",
      "Epoch 31/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.3301 - acc: 0.6043 - val_loss: 1.1873 - val_acc: 0.6540\n",
      "Epoch 32/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.3265 - acc: 0.6059 - val_loss: 1.1554 - val_acc: 0.6536\n",
      "Epoch 33/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.3253 - acc: 0.6084 - val_loss: 1.2047 - val_acc: 0.6369\n",
      "Epoch 34/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.2990 - acc: 0.6117 - val_loss: 1.1601 - val_acc: 0.6530\n",
      "Epoch 35/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.3050 - acc: 0.6114 - val_loss: 1.1949 - val_acc: 0.6428\n",
      "Epoch 36/250\n",
      "303/303 [==============================] - 95s 312ms/step - loss: 1.2837 - acc: 0.6151 - val_loss: 1.1678 - val_acc: 0.6439\n",
      "Epoch 37/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.2847 - acc: 0.6143 - val_loss: 1.1207 - val_acc: 0.6711\n",
      "Epoch 38/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.2754 - acc: 0.6175 - val_loss: 1.1563 - val_acc: 0.6571\n",
      "Epoch 39/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.2999 - acc: 0.6119 - val_loss: 1.1629 - val_acc: 0.6614\n",
      "Epoch 40/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.2781 - acc: 0.6214 - val_loss: 1.1192 - val_acc: 0.6649\n",
      "Epoch 41/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.2503 - acc: 0.6260 - val_loss: 1.1248 - val_acc: 0.6703\n",
      "Epoch 42/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.2586 - acc: 0.6232 - val_loss: 1.1067 - val_acc: 0.6716\n",
      "Epoch 43/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.2390 - acc: 0.6262 - val_loss: 1.1099 - val_acc: 0.6672\n",
      "Epoch 44/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.2397 - acc: 0.6251 - val_loss: 1.1081 - val_acc: 0.6670\n",
      "Epoch 45/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.2287 - acc: 0.6325 - val_loss: 1.0953 - val_acc: 0.6701\n",
      "Epoch 46/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.2204 - acc: 0.6341 - val_loss: 1.0868 - val_acc: 0.6738\n",
      "Epoch 47/250\n",
      "303/303 [==============================] - 95s 312ms/step - loss: 1.2131 - acc: 0.6350 - val_loss: 1.1382 - val_acc: 0.6532\n",
      "Epoch 48/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.2413 - acc: 0.6293 - val_loss: 1.1101 - val_acc: 0.6683\n",
      "Epoch 49/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.2414 - acc: 0.6262 - val_loss: 1.1132 - val_acc: 0.6658\n",
      "Epoch 50/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.2042 - acc: 0.6358 - val_loss: 1.0778 - val_acc: 0.6846\n",
      "Epoch 51/250\n",
      "303/303 [==============================] - 95s 314ms/step - loss: 1.1939 - acc: 0.6365 - val_loss: 1.0957 - val_acc: 0.6833\n",
      "Epoch 52/250\n",
      "303/303 [==============================] - 94s 311ms/step - loss: 1.1905 - acc: 0.6383 - val_loss: 1.0991 - val_acc: 0.6738\n",
      "Epoch 53/250\n",
      "303/303 [==============================] - 95s 314ms/step - loss: 1.2006 - acc: 0.6385 - val_loss: 1.1077 - val_acc: 0.6660\n",
      "Epoch 54/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.1735 - acc: 0.6433 - val_loss: 1.1024 - val_acc: 0.6718\n",
      "Epoch 55/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.1759 - acc: 0.6404 - val_loss: 1.1154 - val_acc: 0.6730\n",
      "Epoch 56/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.1753 - acc: 0.6417 - val_loss: 1.1067 - val_acc: 0.6683\n",
      "Epoch 57/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.1673 - acc: 0.6422 - val_loss: 1.1134 - val_acc: 0.6695\n",
      "Epoch 58/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.1842 - acc: 0.6384 - val_loss: 1.0493 - val_acc: 0.6899\n",
      "Epoch 59/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.1557 - acc: 0.6509 - val_loss: 1.0573 - val_acc: 0.6827\n",
      "Epoch 60/250\n",
      "303/303 [==============================] - 96s 316ms/step - loss: 1.1713 - acc: 0.6455 - val_loss: 1.0268 - val_acc: 0.6978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/250\n",
      "303/303 [==============================] - 95s 313ms/step - loss: 1.1618 - acc: 0.6436 - val_loss: 1.0596 - val_acc: 0.6842\n",
      "Epoch 62/250\n",
      "303/303 [==============================] - 95s 315ms/step - loss: 1.1456 - acc: 0.6504 - val_loss: 1.0315 - val_acc: 0.6854\n",
      "Epoch 63/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.1577 - acc: 0.6488 - val_loss: 1.0344 - val_acc: 0.6945\n",
      "Epoch 64/250\n",
      "303/303 [==============================] - 93s 307ms/step - loss: 1.1393 - acc: 0.6528 - val_loss: 1.0440 - val_acc: 0.6881\n",
      "Epoch 65/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.1477 - acc: 0.6493 - val_loss: 1.0453 - val_acc: 0.6846\n",
      "Epoch 66/250\n",
      "303/303 [==============================] - 99s 328ms/step - loss: 1.1341 - acc: 0.6531 - val_loss: 0.9905 - val_acc: 0.7005\n",
      "Epoch 67/250\n",
      "303/303 [==============================] - 94s 311ms/step - loss: 1.1331 - acc: 0.6548 - val_loss: 1.0595 - val_acc: 0.6862\n",
      "Epoch 68/250\n",
      "303/303 [==============================] - 95s 313ms/step - loss: 1.1257 - acc: 0.6556 - val_loss: 1.0174 - val_acc: 0.6928\n",
      "Epoch 69/250\n",
      "303/303 [==============================] - 95s 314ms/step - loss: 1.1252 - acc: 0.6562 - val_loss: 1.0030 - val_acc: 0.6914\n",
      "Epoch 70/250\n",
      "303/303 [==============================] - 96s 318ms/step - loss: 1.1304 - acc: 0.6548 - val_loss: 1.0193 - val_acc: 0.6935\n",
      "Epoch 71/250\n",
      "303/303 [==============================] - 98s 324ms/step - loss: 1.1047 - acc: 0.6576 - val_loss: 1.0693 - val_acc: 0.6794\n",
      "Epoch 72/250\n",
      "303/303 [==============================] - 95s 315ms/step - loss: 1.1267 - acc: 0.6558 - val_loss: 1.0214 - val_acc: 0.7025\n",
      "Epoch 73/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.1155 - acc: 0.6584 - val_loss: 1.0291 - val_acc: 0.6908\n",
      "Epoch 74/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.1121 - acc: 0.6606 - val_loss: 1.0054 - val_acc: 0.6943\n",
      "Epoch 75/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0944 - acc: 0.6654 - val_loss: 1.0161 - val_acc: 0.6926\n",
      "Epoch 76/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.1134 - acc: 0.6607 - val_loss: 1.0467 - val_acc: 0.6796\n",
      "Epoch 77/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0989 - acc: 0.6630 - val_loss: 1.0488 - val_acc: 0.6860\n",
      "Epoch 78/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.0941 - acc: 0.6624 - val_loss: 1.0120 - val_acc: 0.6992\n",
      "Epoch 79/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.1110 - acc: 0.6609 - val_loss: 1.0227 - val_acc: 0.6951\n",
      "Epoch 80/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.1033 - acc: 0.6609 - val_loss: 1.0385 - val_acc: 0.6914\n",
      "Epoch 81/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0901 - acc: 0.6617 - val_loss: 0.9931 - val_acc: 0.7005\n",
      "Epoch 82/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.1151 - acc: 0.6586 - val_loss: 1.0228 - val_acc: 0.6873\n",
      "Epoch 83/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.0944 - acc: 0.6622 - val_loss: 1.0348 - val_acc: 0.6906\n",
      "Epoch 84/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0925 - acc: 0.6669 - val_loss: 1.0191 - val_acc: 0.6935\n",
      "Epoch 85/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0813 - acc: 0.6663 - val_loss: 0.9873 - val_acc: 0.6992\n",
      "Epoch 86/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0869 - acc: 0.6658 - val_loss: 1.0410 - val_acc: 0.6870\n",
      "Epoch 87/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0879 - acc: 0.6632 - val_loss: 0.9716 - val_acc: 0.7133\n",
      "Epoch 88/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.0711 - acc: 0.6730 - val_loss: 0.9998 - val_acc: 0.6918\n",
      "Epoch 89/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0800 - acc: 0.6716 - val_loss: 0.9909 - val_acc: 0.7001\n",
      "Epoch 90/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0709 - acc: 0.6706 - val_loss: 0.9875 - val_acc: 0.7013\n",
      "Epoch 91/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0744 - acc: 0.6703 - val_loss: 0.9842 - val_acc: 0.6990\n",
      "Epoch 92/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.0686 - acc: 0.6715 - val_loss: 0.9918 - val_acc: 0.7036\n",
      "Epoch 93/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0593 - acc: 0.6714 - val_loss: 0.9948 - val_acc: 0.6980\n",
      "Epoch 94/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0599 - acc: 0.6735 - val_loss: 0.9930 - val_acc: 0.7058\n",
      "Epoch 95/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.0733 - acc: 0.6706 - val_loss: 1.0196 - val_acc: 0.6970\n",
      "Epoch 96/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0657 - acc: 0.6698 - val_loss: 0.9848 - val_acc: 0.6963\n",
      "Epoch 97/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0541 - acc: 0.6753 - val_loss: 1.0168 - val_acc: 0.7011\n",
      "Epoch 98/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.0612 - acc: 0.6725 - val_loss: 1.0015 - val_acc: 0.6978\n",
      "Epoch 99/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0521 - acc: 0.6746 - val_loss: 0.9813 - val_acc: 0.7021\n",
      "Epoch 100/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0538 - acc: 0.6731 - val_loss: 0.9665 - val_acc: 0.7083\n",
      "Epoch 101/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0507 - acc: 0.6746 - val_loss: 0.9736 - val_acc: 0.7096\n",
      "Epoch 102/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.1418 - acc: 0.6545 - val_loss: 0.9889 - val_acc: 0.7077\n",
      "Epoch 103/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0947 - acc: 0.6671 - val_loss: 0.9488 - val_acc: 0.7094\n",
      "Epoch 104/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0682 - acc: 0.6726 - val_loss: 0.9807 - val_acc: 0.7073\n",
      "Epoch 105/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0634 - acc: 0.6716 - val_loss: 0.9722 - val_acc: 0.7110\n",
      "Epoch 106/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0656 - acc: 0.6766 - val_loss: 0.9962 - val_acc: 0.7001\n",
      "Epoch 107/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0517 - acc: 0.6739 - val_loss: 1.0048 - val_acc: 0.7019\n",
      "Epoch 108/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0592 - acc: 0.6723 - val_loss: 1.0005 - val_acc: 0.7042\n",
      "Epoch 109/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.0488 - acc: 0.6719 - val_loss: 0.9754 - val_acc: 0.7172\n",
      "Epoch 110/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0481 - acc: 0.6763 - val_loss: 0.9842 - val_acc: 0.7017\n",
      "Epoch 111/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.0483 - acc: 0.6766 - val_loss: 1.0220 - val_acc: 0.7001\n",
      "Epoch 112/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.0476 - acc: 0.6725 - val_loss: 1.0140 - val_acc: 0.6961\n",
      "Epoch 113/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0462 - acc: 0.6722 - val_loss: 1.0149 - val_acc: 0.6957\n",
      "Epoch 114/250\n",
      "303/303 [==============================] - 93s 307ms/step - loss: 1.0504 - acc: 0.6737 - val_loss: 0.9606 - val_acc: 0.7063\n",
      "Epoch 115/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0245 - acc: 0.6788 - val_loss: 1.0208 - val_acc: 0.6974\n",
      "Epoch 116/250\n",
      "303/303 [==============================] - 93s 309ms/step - loss: 1.0394 - acc: 0.6792 - val_loss: 0.9898 - val_acc: 0.7038\n",
      "Epoch 117/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0393 - acc: 0.6788 - val_loss: 0.9969 - val_acc: 0.7021\n",
      "Epoch 118/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0508 - acc: 0.6769 - val_loss: 0.9713 - val_acc: 0.7050\n",
      "Epoch 119/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0367 - acc: 0.6787 - val_loss: 0.9567 - val_acc: 0.7065\n",
      "Epoch 120/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0408 - acc: 0.6762 - val_loss: 0.9443 - val_acc: 0.7174\n",
      "Epoch 121/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0338 - acc: 0.6823 - val_loss: 0.9626 - val_acc: 0.7100\n",
      "Epoch 122/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0256 - acc: 0.6774 - val_loss: 0.9606 - val_acc: 0.7108\n",
      "Epoch 123/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0259 - acc: 0.6811 - val_loss: 0.9804 - val_acc: 0.7046\n",
      "Epoch 124/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0332 - acc: 0.6786 - val_loss: 0.9685 - val_acc: 0.7065\n",
      "Epoch 125/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0262 - acc: 0.6795 - val_loss: 0.9633 - val_acc: 0.7118\n",
      "Epoch 126/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0227 - acc: 0.6838 - val_loss: 0.9409 - val_acc: 0.7131\n",
      "Epoch 127/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0316 - acc: 0.6793 - val_loss: 0.9920 - val_acc: 0.7112\n",
      "Epoch 128/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0168 - acc: 0.6856 - val_loss: 0.9827 - val_acc: 0.7034\n",
      "Epoch 129/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0173 - acc: 0.6835 - val_loss: 0.9325 - val_acc: 0.7191\n",
      "Epoch 130/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0247 - acc: 0.6833 - val_loss: 0.9758 - val_acc: 0.7073\n",
      "Epoch 131/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0176 - acc: 0.6819 - val_loss: 1.0008 - val_acc: 0.6943\n",
      "Epoch 132/250\n",
      "303/303 [==============================] - 94s 310ms/step - loss: 1.0150 - acc: 0.6867 - val_loss: 0.9805 - val_acc: 0.7110\n",
      "Epoch 133/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0111 - acc: 0.6810 - val_loss: 0.9613 - val_acc: 0.7141\n",
      "Epoch 134/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0185 - acc: 0.6818 - val_loss: 0.9424 - val_acc: 0.7236\n",
      "Epoch 135/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0238 - acc: 0.6852 - val_loss: 0.9789 - val_acc: 0.7092\n",
      "Epoch 136/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0029 - acc: 0.6863 - val_loss: 0.9717 - val_acc: 0.7125\n",
      "Epoch 137/250\n",
      "303/303 [==============================] - 93s 308ms/step - loss: 1.0124 - acc: 0.6847 - val_loss: 0.9465 - val_acc: 0.7166\n",
      "Epoch 138/250\n",
      "303/303 [==============================] - 94s 309ms/step - loss: 1.0095 - acc: 0.6871 - val_loss: 0.9422 - val_acc: 0.7143\n",
      "Epoch 139/250\n",
      "303/303 [==============================] - 93s 307ms/step - loss: 1.0006 - acc: 0.6835 - val_loss: 0.9434 - val_acc: 0.7222\n",
      "Epoch 140/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 1.0160 - acc: 0.6857 - val_loss: 0.9442 - val_acc: 0.7195\n",
      "Epoch 141/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 1.0068 - acc: 0.6891 - val_loss: 0.9468 - val_acc: 0.7207\n",
      "Epoch 142/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9950 - acc: 0.6910 - val_loss: 0.9520 - val_acc: 0.7170\n",
      "Epoch 143/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 1.0060 - acc: 0.6854 - val_loss: 0.9498 - val_acc: 0.7098\n",
      "Epoch 144/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 1.0089 - acc: 0.6874 - val_loss: 0.9670 - val_acc: 0.7023\n",
      "Epoch 145/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 1.0147 - acc: 0.6837 - val_loss: 0.9718 - val_acc: 0.7096\n",
      "Epoch 146/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 1.0013 - acc: 0.6890 - val_loss: 0.9264 - val_acc: 0.7180\n",
      "Epoch 147/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 1.0029 - acc: 0.6868 - val_loss: 0.9600 - val_acc: 0.7034\n",
      "Epoch 148/250\n",
      "303/303 [==============================] - 93s 307ms/step - loss: 1.0012 - acc: 0.6877 - val_loss: 0.9783 - val_acc: 0.7085\n",
      "Epoch 149/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 1.0071 - acc: 0.6862 - val_loss: 0.9853 - val_acc: 0.7145\n",
      "Epoch 150/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9931 - acc: 0.6886 - val_loss: 0.9020 - val_acc: 0.7277\n",
      "Epoch 151/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 1.0008 - acc: 0.6853 - val_loss: 0.9486 - val_acc: 0.7122\n",
      "Epoch 152/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9935 - acc: 0.6927 - val_loss: 0.9580 - val_acc: 0.7255\n",
      "Epoch 153/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9968 - acc: 0.6852 - val_loss: 0.9388 - val_acc: 0.7197\n",
      "Epoch 154/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9919 - acc: 0.6917 - val_loss: 0.9621 - val_acc: 0.7133\n",
      "Epoch 155/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 1.0052 - acc: 0.6854 - val_loss: 1.0019 - val_acc: 0.7092\n",
      "Epoch 156/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9959 - acc: 0.6881 - val_loss: 0.9380 - val_acc: 0.7199\n",
      "Epoch 157/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9963 - acc: 0.6906 - val_loss: 0.9281 - val_acc: 0.7209\n",
      "Epoch 158/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9917 - acc: 0.6885 - val_loss: 0.9574 - val_acc: 0.7114\n",
      "Epoch 159/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9878 - acc: 0.6920 - val_loss: 0.9620 - val_acc: 0.7172\n",
      "Epoch 160/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9839 - acc: 0.6963 - val_loss: 0.9719 - val_acc: 0.7151\n",
      "Epoch 161/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9912 - acc: 0.6913 - val_loss: 0.9590 - val_acc: 0.7127\n",
      "Epoch 162/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9847 - acc: 0.6932 - val_loss: 0.9720 - val_acc: 0.7215\n",
      "Epoch 163/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9789 - acc: 0.6928 - val_loss: 0.9395 - val_acc: 0.7141\n",
      "Epoch 164/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9844 - acc: 0.6904 - val_loss: 0.9313 - val_acc: 0.7234\n",
      "Epoch 165/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9828 - acc: 0.6946 - val_loss: 0.9204 - val_acc: 0.7215\n",
      "Epoch 166/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9763 - acc: 0.6959 - val_loss: 0.9462 - val_acc: 0.7174\n",
      "Epoch 167/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9828 - acc: 0.6932 - val_loss: 0.9606 - val_acc: 0.7160\n",
      "Epoch 168/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9842 - acc: 0.6891 - val_loss: 1.0069 - val_acc: 0.7096\n",
      "Epoch 169/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9838 - acc: 0.6915 - val_loss: 0.9892 - val_acc: 0.7112\n",
      "Epoch 170/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9785 - acc: 0.6922 - val_loss: 0.9882 - val_acc: 0.7058\n",
      "Epoch 171/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9792 - acc: 0.6889 - val_loss: 0.9259 - val_acc: 0.7226\n",
      "Epoch 172/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9921 - acc: 0.6887 - val_loss: 0.9710 - val_acc: 0.7120\n",
      "Epoch 173/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9899 - acc: 0.6856 - val_loss: 0.9635 - val_acc: 0.7127\n",
      "Epoch 174/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9698 - acc: 0.6944 - val_loss: 0.9808 - val_acc: 0.7184\n",
      "Epoch 175/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9873 - acc: 0.6929 - val_loss: 0.9207 - val_acc: 0.7226\n",
      "Epoch 176/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9705 - acc: 0.6963 - val_loss: 0.9765 - val_acc: 0.7081\n",
      "Epoch 177/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9778 - acc: 0.6949 - val_loss: 0.9512 - val_acc: 0.7135\n",
      "Epoch 178/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9737 - acc: 0.6974 - val_loss: 0.9611 - val_acc: 0.7139\n",
      "Epoch 179/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9689 - acc: 0.6934 - val_loss: 0.9644 - val_acc: 0.7131\n",
      "Epoch 180/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9788 - acc: 0.6950 - val_loss: 0.9299 - val_acc: 0.7197\n",
      "Epoch 181/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9734 - acc: 0.6945 - val_loss: 0.9390 - val_acc: 0.7153\n",
      "Epoch 182/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9669 - acc: 0.6999 - val_loss: 0.9329 - val_acc: 0.7199\n",
      "Epoch 183/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9754 - acc: 0.6916 - val_loss: 0.9386 - val_acc: 0.7199\n",
      "Epoch 184/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9647 - acc: 0.7018 - val_loss: 0.9879 - val_acc: 0.7174\n",
      "Epoch 185/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9606 - acc: 0.6984 - val_loss: 0.9423 - val_acc: 0.7197\n",
      "Epoch 186/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9682 - acc: 0.6952 - val_loss: 0.9302 - val_acc: 0.7195\n",
      "Epoch 187/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9566 - acc: 0.6986 - val_loss: 0.9279 - val_acc: 0.7193\n",
      "Epoch 188/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9681 - acc: 0.6979 - val_loss: 0.9439 - val_acc: 0.7193\n",
      "Epoch 189/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9672 - acc: 0.6946 - val_loss: 0.9261 - val_acc: 0.7228\n",
      "Epoch 190/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9558 - acc: 0.7004 - val_loss: 0.9378 - val_acc: 0.7145\n",
      "Epoch 191/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9671 - acc: 0.6963 - val_loss: 0.9226 - val_acc: 0.7238\n",
      "Epoch 192/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9654 - acc: 0.6932 - val_loss: 0.9671 - val_acc: 0.7201\n",
      "Epoch 193/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9661 - acc: 0.6966 - val_loss: 1.0186 - val_acc: 0.7079\n",
      "Epoch 194/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9637 - acc: 0.6991 - val_loss: 0.9385 - val_acc: 0.7133\n",
      "Epoch 195/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9633 - acc: 0.6975 - val_loss: 0.9426 - val_acc: 0.7220\n",
      "Epoch 196/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9529 - acc: 0.6969 - val_loss: 0.9216 - val_acc: 0.7263\n",
      "Epoch 197/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9549 - acc: 0.6973 - val_loss: 0.9216 - val_acc: 0.7253\n",
      "Epoch 198/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9703 - acc: 0.6938 - val_loss: 0.9470 - val_acc: 0.7141\n",
      "Epoch 199/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9625 - acc: 0.6965 - val_loss: 0.9270 - val_acc: 0.7193\n",
      "Epoch 200/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9488 - acc: 0.7002 - val_loss: 0.9293 - val_acc: 0.7267\n",
      "Epoch 201/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9626 - acc: 0.6971 - val_loss: 0.9295 - val_acc: 0.7205\n",
      "Epoch 202/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9543 - acc: 0.6982 - val_loss: 0.9348 - val_acc: 0.7193\n",
      "Epoch 203/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9566 - acc: 0.6947 - val_loss: 0.9716 - val_acc: 0.7098\n",
      "Epoch 204/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9517 - acc: 0.6993 - val_loss: 1.0054 - val_acc: 0.7071\n",
      "Epoch 205/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9581 - acc: 0.6962 - val_loss: 0.9751 - val_acc: 0.7104\n",
      "Epoch 206/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9475 - acc: 0.7036 - val_loss: 0.9411 - val_acc: 0.7209\n",
      "Epoch 207/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9547 - acc: 0.6977 - val_loss: 0.9284 - val_acc: 0.7193\n",
      "Epoch 208/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9489 - acc: 0.7010 - val_loss: 0.9596 - val_acc: 0.7151\n",
      "Epoch 209/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9516 - acc: 0.7028 - val_loss: 0.9358 - val_acc: 0.7259\n",
      "Epoch 210/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9496 - acc: 0.7005 - val_loss: 0.9623 - val_acc: 0.7236\n",
      "Epoch 211/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9458 - acc: 0.6998 - val_loss: 0.9124 - val_acc: 0.7203\n",
      "Epoch 212/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9566 - acc: 0.6955 - val_loss: 0.9304 - val_acc: 0.7226\n",
      "Epoch 213/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9350 - acc: 0.7068 - val_loss: 0.9286 - val_acc: 0.7104\n",
      "Epoch 214/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9515 - acc: 0.7042 - val_loss: 0.9243 - val_acc: 0.7197\n",
      "Epoch 215/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9447 - acc: 0.7047 - val_loss: 0.9910 - val_acc: 0.7184\n",
      "Epoch 216/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9341 - acc: 0.7076 - val_loss: 0.9788 - val_acc: 0.7007\n",
      "Epoch 217/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9478 - acc: 0.7040 - val_loss: 0.9770 - val_acc: 0.7075\n",
      "Epoch 218/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9377 - acc: 0.7059 - val_loss: 0.9441 - val_acc: 0.7238\n",
      "Epoch 219/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9350 - acc: 0.7050 - val_loss: 0.9559 - val_acc: 0.7201\n",
      "Epoch 220/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9471 - acc: 0.7058 - val_loss: 0.9307 - val_acc: 0.7275\n",
      "Epoch 221/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9458 - acc: 0.7018 - val_loss: 0.9540 - val_acc: 0.7166\n",
      "Epoch 222/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9534 - acc: 0.7011 - val_loss: 0.9766 - val_acc: 0.7034\n",
      "Epoch 223/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9356 - acc: 0.7033 - val_loss: 0.9347 - val_acc: 0.7234\n",
      "Epoch 224/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9592 - acc: 0.7006 - val_loss: 0.9970 - val_acc: 0.7071\n",
      "Epoch 225/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9371 - acc: 0.7037 - val_loss: 0.9349 - val_acc: 0.7168\n",
      "Epoch 226/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9360 - acc: 0.7025 - val_loss: 0.9515 - val_acc: 0.7207\n",
      "Epoch 227/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9387 - acc: 0.7018 - val_loss: 0.9807 - val_acc: 0.7218\n",
      "Epoch 228/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9297 - acc: 0.7098 - val_loss: 0.9136 - val_acc: 0.7310\n",
      "Epoch 229/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9262 - acc: 0.7063 - val_loss: 0.9395 - val_acc: 0.7164\n",
      "Epoch 230/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9321 - acc: 0.7077 - val_loss: 0.9076 - val_acc: 0.7234\n",
      "Epoch 231/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9342 - acc: 0.7064 - val_loss: 0.9476 - val_acc: 0.7180\n",
      "Epoch 232/250\n",
      "303/303 [==============================] - 93s 307ms/step - loss: 0.9398 - acc: 0.7027 - val_loss: 0.8935 - val_acc: 0.7350\n",
      "Epoch 233/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9440 - acc: 0.6991 - val_loss: 0.9218 - val_acc: 0.7321\n",
      "Epoch 234/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9384 - acc: 0.7022 - val_loss: 0.9377 - val_acc: 0.7172\n",
      "Epoch 235/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9423 - acc: 0.7022 - val_loss: 0.9396 - val_acc: 0.7255\n",
      "Epoch 236/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9390 - acc: 0.7035 - val_loss: 0.9641 - val_acc: 0.7269\n",
      "Epoch 237/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9480 - acc: 0.7017 - val_loss: 0.9437 - val_acc: 0.7232\n",
      "Epoch 238/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 93s 307ms/step - loss: 0.9371 - acc: 0.7041 - val_loss: 0.9394 - val_acc: 0.7218\n",
      "Epoch 239/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9289 - acc: 0.7066 - val_loss: 0.9314 - val_acc: 0.7325\n",
      "Epoch 240/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9467 - acc: 0.7016 - val_loss: 0.9274 - val_acc: 0.7242\n",
      "Epoch 241/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9218 - acc: 0.7080 - val_loss: 0.9495 - val_acc: 0.7255\n",
      "Epoch 242/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9370 - acc: 0.7027 - val_loss: 0.9250 - val_acc: 0.7207\n",
      "Epoch 243/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9193 - acc: 0.7080 - val_loss: 0.9246 - val_acc: 0.7178\n",
      "Epoch 244/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9361 - acc: 0.7029 - val_loss: 0.9108 - val_acc: 0.7304\n",
      "Epoch 245/250\n",
      "303/303 [==============================] - 93s 307ms/step - loss: 0.9315 - acc: 0.7042 - val_loss: 0.9414 - val_acc: 0.7352\n",
      "Epoch 246/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9417 - acc: 0.7007 - val_loss: 0.9348 - val_acc: 0.7242\n",
      "Epoch 247/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9322 - acc: 0.7079 - val_loss: 0.9085 - val_acc: 0.7290\n",
      "Epoch 248/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9299 - acc: 0.7031 - val_loss: 0.9964 - val_acc: 0.7147\n",
      "Epoch 249/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9337 - acc: 0.7052 - val_loss: 0.9270 - val_acc: 0.7263\n",
      "Epoch 250/250\n",
      "303/303 [==============================] - 93s 306ms/step - loss: 0.9546 - acc: 0.7000 - val_loss: 0.9131 - val_acc: 0.7335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23c8064b8d0>"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 250\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        preprocessing_function=random_rot90)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "steps_per_epoch = int(np.ceil(X_train.shape[0] / float(batch_size)))\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow() ==> Realtime data augmentation\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size), \n",
    "                    epochs=epochs, validation_data=(X_val, Y_val), verbose=1, \n",
    "                            steps_per_epoch=steps_per_epoch, workers=4, callbacks=[tbCallback, checkpointCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model('best_model_checkpoint.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4841/4841 [==============================] - 10s 2ms/step\n",
      "Test loss: 0.893533925494\n",
      "Test accuracy: 0.734972113224\n"
     ]
    }
   ],
   "source": [
    "# Score trained model\n",
    "\n",
    "scores = model.evaluate(X_val, Y_val, verbose=1)\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "df_submit = pd.DataFrame(list(zip(test_img_names, y_pred)),columns=['image','class'])\n",
    "df_submit.to_csv('submission', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
